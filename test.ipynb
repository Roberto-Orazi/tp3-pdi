{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\jonat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jonat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jonat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jonat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jonat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\jonat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jonat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\jonat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jonat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jonat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jonat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\jonat\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\jonat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\jonat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from opencv-python) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\jonat\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\jonat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\jonat\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "!pip install opencv-python\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos función para mostrar imágenes\n",
    "def imshow(img, new_fig=True, title=None, color_img=False, blocking=False, colorbar=False, ticks=False):\n",
    "    if new_fig:  \n",
    "        plt.figure()  # Crea una nueva figura si new_fig es True.\n",
    "    if color_img:  \n",
    "        plt.imshow(img)  # Muestra la imagen en colores.\n",
    "    else:\n",
    "        plt.imshow(img, cmap='gray')  # Muestra la imagen en escala de grises.\n",
    "    plt.title(title)  # Agrega un título si se proporciona.\n",
    "    if not ticks:  \n",
    "        plt.xticks([]), plt.yticks([])  # Oculta los ejes si ticks es False.\n",
    "    if colorbar:  \n",
    "        plt.colorbar()  # Agrega una barra de color si colorbar es True.\n",
    "    if new_fig:  \n",
    "        plt.show(block=blocking)  # Muestra la figura y bloquea la ejecución según el parámetro blocking.\n",
    "\n",
    "# Reconstrucción morfológica\n",
    "def imreconstruct(marker, mask, kernel=None):\n",
    "    # Asegurarse de que marker y mask sean del mismo tamaño y tipo\n",
    "    if marker.shape != mask.shape:\n",
    "        raise ValueError(\"El tamaño de 'marker' y 'mask' debe ser igual\")  # Valida dimensiones iguales.\n",
    "    if marker.dtype != mask.dtype:\n",
    "        marker = marker.astype(mask.dtype)  # Convierte el tipo de datos de marker para que coincida con mask.\n",
    "\n",
    "    # Definir el kernel si no se proporciona\n",
    "    if kernel is None:\n",
    "        kernel = np.ones((3, 3), np.uint8)  # Define un kernel de 3x3 si no se pasa uno.\n",
    "\n",
    "    while True:\n",
    "        expanded = cv2.dilate(marker, kernel)  # Realiza una dilatación sobre el marcador.\n",
    "        expanded_intersection = cv2.bitwise_and(expanded, mask)  # Calcula la intersección con la máscara.\n",
    "        if np.array_equal(marker, expanded_intersection):  # Verifica si no hay cambios en la iteración.\n",
    "            break\n",
    "        marker = expanded_intersection  # Actualiza el marcador con la intersección.\n",
    "    return expanded_intersection  # Devuelve el resultado final de la reconstrucción.\n",
    "\n",
    "# Relleno de huecos en imágenes binarias\n",
    "def imfillhole(img):\n",
    "    mask = np.zeros_like(img)  # Genera una máscara vacía con las mismas dimensiones que la imagen.\n",
    "    mask = cv2.copyMakeBorder(mask[1:-1, 1:-1], 1, 1, 1, 1, cv2.BORDER_CONSTANT, value=int(255))  \n",
    "    # Crea bordes constantes blancos alrededor de la máscara.\n",
    "    marker = cv2.bitwise_not(img, mask=mask)  # Calcula el complemento de los bordes como marcador.\n",
    "    img_c = cv2.bitwise_not(img)  # Obtiene el complemento de la imagen original como máscara.\n",
    "    img_r = imreconstruct(marker=marker, mask=img_c)  # Realiza la reconstrucción usando el marcador y la máscara.\n",
    "    img_fh = cv2.bitwise_not(img_r)  # Toma el complemento de la reconstrucción para obtener la imagen final.\n",
    "    return img_fh  # Devuelve la imagen binaria con los huecos rellenos.\n",
    "\n",
    "# Comparación de movimiento entre cuadros consecutivos\n",
    "def se_mueve_no_se_mueve(foto, centroides):\n",
    "    anterior = ''  # Inicializa la variable para almacenar los centroides del cuadro anterior.\n",
    "    actual = ''  # Inicializa la variable para almacenar los centroides del cuadro actual.\n",
    "    lista = []  # Lista para almacenar los identificadores de los objetos que no se han movido.\n",
    "    for i in centroides:  # Recorre los datos de los centroides.\n",
    "        if i[0] == (foto-1):  \n",
    "            anterior = i  # Encuentra los centroides correspondientes al cuadro anterior.\n",
    "        if i[0] == foto:\n",
    "            actual = i  # Encuentra los centroides del cuadro actual.\n",
    "            break\n",
    "    if anterior == '' or actual == '':  # Si no se encontraron datos para uno de los cuadros, devuelve una lista vacía.\n",
    "        return lista\n",
    "    \n",
    "    ant_cen = anterior[1]  # Obtiene los centroides del cuadro anterior.\n",
    "    act_cen = actual[1]  # Obtiene los centroides del cuadro actual.\n",
    "    for j in range(len(ant_cen)):  # Recorre todos los centroides del cuadro anterior.\n",
    "        if (act_cen[j][1][0]-20.0) < ant_cen[j][1][0] < (act_cen[j][1][0]+20.0) and \\\n",
    "           (act_cen[j][1][1]-20.0) < ant_cen[j][1][1] < (act_cen[j][1][1]+20.0):  \n",
    "           # Verifica si la posición del centroide actual está dentro de un rango cercano al anterior.\n",
    "            lista.append(act_cen[j][0])  # Agrega el identificador del objeto a la lista si cumple la condición.\n",
    "    return lista  # Devuelve la lista con los identificadores de los objetos estacionarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_imagenes(num_foto, frame, num_foto_centroides_dados=[]):\n",
    "    # FUNCIONALIDAD PRINCIPAL: Procesar una imagen para detectar dados y determinar el valor de sus caras.\n",
    "\n",
    "    # Listado para almacenar el valor de las caras de los dados en cada cuadro.\n",
    "    num_cara_caja = []\n",
    "\n",
    "    # Convertir la imagen de BGR a RGB y luego a escala de grises.\n",
    "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Aplicar umbral para segmentar áreas de interés.\n",
    "    _, thresh = cv2.threshold(img_gray, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Aplicar el detector de bordes Canny para identificar bordes generales.\n",
    "    canny = cv2.Canny(img_gray, 50, 75)\n",
    "    engrosar_bordes_generales = cv2.dilate(canny, np.ones((17, 17), np.uint8))\n",
    "\n",
    "    # Rellenar huecos en los bordes detectados.\n",
    "    relleno_dados = imfillhole(engrosar_bordes_generales)\n",
    "\n",
    "    # Erosionar los bordes para eliminar ruido y reducir detalles.\n",
    "    erocion_dado = cv2.erode(relleno_dados, np.ones((3, 3), np.uint8))\n",
    "\n",
    "    # SEGMENTACIÓN PARA DETECTAR CÍRCULOS (CARAS DE LOS DADOS).\n",
    "    canny_circulos = cv2.Canny(img_gray, 175, 255)\n",
    "    engrosar_circulos = cv2.dilate(canny_circulos, np.ones((3, 3), np.uint8))\n",
    "    relleno_circulos = imfillhole(engrosar_circulos)\n",
    "    erocion_circulos = cv2.erode(relleno_circulos, np.ones((5, 5), np.uint8))\n",
    "\n",
    "    # OBTENER BOUNDING BOXES DE LOS DADOS.\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(erocion_dado)\n",
    "\n",
    "    # Filtrar componentes conectados basados en criterios geométricos y de área.\n",
    "    indice_stats = []  # Almacena índices de las estadísticas que cumplen las condiciones.\n",
    "    centroides_dados = []  # Almacena los centroides de los dados detectados.\n",
    "    for i in range(1, num_labels):  # Omitir el fondo (label 0).\n",
    "        x, y, w, h, area = stats[i]  # Coordenadas y área del bounding box.\n",
    "        if 50 < w < 120 and 50 < h < 140:  # Filtrar por tamaño del bounding box.\n",
    "            factor_forma = w / h\n",
    "            if 0.5 < factor_forma < 2:  # Filtrar por proporción del bounding box.\n",
    "                if 4500 < area < 11000:  # Filtrar por área.\n",
    "                    indice_stats.append(i)\n",
    "                    centroides_dados.append([i, centroids[i]])\n",
    "\n",
    "    # Guardar información de los centroides si hay suficientes dados detectados.\n",
    "    if len(centroides_dados) >= 5:\n",
    "        num_foto_centroides_dados.append([num_foto, centroides_dados])\n",
    "\n",
    "    # DETERMINAR SI LOS DADOS ESTÁN ESTACIONARIOS ENTRE CUADROS.\n",
    "    if len(num_foto_centroides_dados) >= 2:\n",
    "        lista = se_mueve_no_se_mueve(num_foto, num_foto_centroides_dados)\n",
    "\n",
    "        # CALCULAR EL VALOR DE LA CARA PARA LOS DADOS ESTACIONARIOS.\n",
    "        num_cara_caja = []\n",
    "        for j in lista:\n",
    "            x2, y2, w2, h2, area2 = stats[j]\n",
    "            img_circulos = np.zeros_like(img_gray)  # Imagen vacía para análisis de círculos.\n",
    "            img_circulos[y2:y2 + h2, x2:x2 + w2] = erocion_circulos[y2:y2 + h2, x2:x2 + w2]\n",
    "\n",
    "            # Detectar componentes conectados en la región del dado.\n",
    "            num_labels_2, labels_2, stats_2, centroids_2 = cv2.connectedComponentsWithStats(img_circulos)\n",
    "            cara_dado = 0  # Inicializar contador para las caras del dado.\n",
    "            for i_label in range(1, num_labels_2):\n",
    "                area_circulos = stats_2[i_label, cv2.CC_STAT_AREA]\n",
    "                if 30 < area_circulos < 150:  # Filtrar por tamaño de los círculos.\n",
    "                    mask = (labels_2 == i_label).astype(np.uint8) * 255\n",
    "                    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "                    for contour in contours:\n",
    "                        perimetro_circulo = cv2.arcLength(contour, True)\n",
    "                        factor_forma_circulo = area_circulos / (perimetro_circulo ** 2)\n",
    "                        if 0.050 < factor_forma_circulo < 0.10:  # Filtrar por forma circular.\n",
    "                            cara_dado += 1\n",
    "            num_cara_caja.append([j, cara_dado])\n",
    "\n",
    "    # DIBUJAR BOUNDING BOXES Y ETIQUETAS SOBRE LOS DADOS.\n",
    "    if len(indice_stats) >= 5:\n",
    "        for k in indice_stats:\n",
    "            x3, y3, w3, h3, area3 = stats[k]\n",
    "            punto1 = (x3, y3)  # Esquina superior izquierda del bounding box.\n",
    "            punto2 = (x3 + w3, y3 + h3)  # Esquina inferior derecha.\n",
    "            if not num_cara_caja:\n",
    "                # Dibujar bounding box en rojo si no se ha detectado cara.\n",
    "                cv2.rectangle(img_rgb, punto1, punto2, color=(0, 0, 255), thickness=5)\n",
    "            else:\n",
    "                for g in num_cara_caja:\n",
    "                    if k != g[0]:\n",
    "                        cv2.rectangle(img_rgb, punto1, punto2, color=(0, 0, 255), thickness=5)\n",
    "                    else:\n",
    "                        cv2.rectangle(img_rgb, punto1, punto2, color=(0, 0, 255), thickness=5)\n",
    "                        cv2.putText(img_rgb, f'Valor es: {g[1]}', (x3 - 10, y3 - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                    fontScale=1, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "    # Convertir la imagen procesada de nuevo a BGR para guardar o visualizar.\n",
    "    terminada = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
    "    return terminada, num_foto_centroides_dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(\"frames\", exist_ok = True)  # Si no existe, crea la carpeta 'frames' en el directorio actual (comentado actualmente).\n",
    "\n",
    "# --- Leer un video ------------------------------------------------\n",
    "for num_video in range(1, 5):  # Itera sobre los nombres de los videos ('tirada_1.mp4' a 'tirada_4.mp4').\n",
    "    cap = cv2.VideoCapture(f'tirada_{num_video}.mp4')  # Abre el archivo de video correspondiente.\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # Obtiene el ancho del video en píxeles.\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # Obtiene la altura del video en píxeles.\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))  # Obtiene los cuadros por segundo (FPS) del video.\n",
    "    n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Obtiene el número total de frames en el video.\n",
    "    frame_number = 0  # Inicializa el contador de frames.\n",
    "    \n",
    "    # Crea un objeto para guardar el video procesado con las mismas propiedades del original.\n",
    "    out = cv2.VideoWriter(f'Video{num_video}-procesado.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "    num_foto_centroides_dados = []  # Lista para almacenar información de los centroides de los dados por frame.\n",
    "    bandera = True  # Bandera para determinar el área útil solo una vez.\n",
    "\n",
    "    while cap.isOpened():  # Repite mientras el archivo de video esté abierto.\n",
    "        ret, frame = cap.read()  # Lee el siguiente frame del video. 'ret' indica éxito (True/False).\n",
    "        if ret == True:  # Verifica si se leyó el frame correctamente.\n",
    "            if bandera:  # Si es el primer frame, calcula el área útil donde están los dados.\n",
    "                ancho = int(len(frame[0]) / 2)  # Obtiene el punto medio horizontal del frame.\n",
    "                cont = 0  # Contador para encontrar el límite superior de la región útil.\n",
    "                for j in range(len(frame)):  # Itera sobre las filas de píxeles en el frame.\n",
    "                    if frame[j][ancho][2] < 50:  # Comprueba si el canal rojo es menor a 50 (indicio de borde útil).\n",
    "                        cont += 1  # Incrementa el contador si cumple la condición.\n",
    "                bandera = False  # Cambia la bandera para no repetir este cálculo en siguientes frames.\n",
    "\n",
    "            largo = len(frame[0])  # Obtiene el ancho total del frame.\n",
    "            \n",
    "            # Procesa la región útil del frame para detectar y analizar los dados.\n",
    "            foto_recortada, num_foto_centroides_dados = procesar_imagenes(\n",
    "                frame_number, frame[0:cont, 0:largo], num_foto_centroides_dados\n",
    "            )\n",
    "\n",
    "            frame_number += 1  # Incrementa el contador de frames procesados.\n",
    "            frame[0:cont, 0:largo] = foto_recortada  # Actualiza la región útil del frame con los resultados procesados.\n",
    "            out.write(frame)  # Escribe el frame procesado en el archivo de salida.\n",
    "        else:  \n",
    "            break  # Detiene el bucle si no hay más frames.\n",
    "\n",
    "    cap.release()  # Libera el archivo de video original.\n",
    "    out.release()  # Libera el archivo de video procesado.\n",
    "    cv2.destroyAllWindows()  # Cierra todas las ventanas abiertas por OpenCV.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
